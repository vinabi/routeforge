{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsdznf-D6rYP"
      },
      "source": [
        "# **Nayab Irfan | RouteForge**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "> AgenticAI Cohort 2 | Assignment 1\n",
        "Assignment: AI Research & Planning Agent | Travel Agent\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxl7wgM9LPC-"
      },
      "source": [
        "**Methodolody → find places → optimize route cost → maximize fun → arrive**\n",
        "###### Tools used:\n",
        " - Tavily (primary) & SerpAPI (fallback) for search (last 12 months intent)\n",
        " - SerpAPI Google Maps (if key present) for places; Overpass (OSM) fallback\n",
        " - OSRM (public) for routing & distance/time (no key required)\n",
        " - OpenAI LLM for itinerary (Groq fallback)\n",
        " - LangChain tools + tool-calling agent to show multi-step planning\n",
        "\n",
        " Outputs:\n",
        " - Report.md  (final trip plan)\n",
        " - trip_plan.json (all sources, chosen places, route, costs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxKAwTJuLA6d"
      },
      "source": [
        "#### **INSTALLS**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3kYcWSaeLKa7",
        "outputId": "410075f9-9d79-4d49-9eb2-f8c82c8335d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.30)\n",
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.11/dist-packages (0.3.7)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.74 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.74)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.99.9)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.11.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (0.4.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (25.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (2.11.7)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.74->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.99.9->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain-openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain-openai) (0.4.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: groq<1,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from langchain-groq) (0.31.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain-openai) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain-openai) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.5.0)\n",
            "\u001b[31mERROR: Cannot install langchain-groq==0.1.3, langchain-openai==0.1.23 and langchain==0.2.13 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install langchain-openai langchain-groq\n",
        "!pip -q install --upgrade pip\n",
        "!pip -q install \\\n",
        "  langchain==0.2.13 \\\n",
        "  langchain-openai==0.1.23 \\\n",
        "  langchain-groq==0.1.3 \\\n",
        "  langchain-community==0.2.9 \\\n",
        "  tavily-python==0.3.6 \\\n",
        "  serpapi==0.1.5 \\\n",
        "  requests==2.32.3 \\\n",
        "  tiktoken==0.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TFbEozQ-Mm8S",
        "outputId": "d23470bd-7f05-4bb1-9075-5aa9f9a95c13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tavily-python in /usr/local/lib/python3.11/dist-packages (0.7.10)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from tavily-python) (2.32.3)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.11.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.28.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (2025.8.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->tavily-python) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->tavily-python) (4.14.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install tavily-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HunZWOJQK5PE"
      },
      "source": [
        "#### **1) IMPORTS & SETUP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "collapsed": true,
        "id": "IhXkvYS0IZiS"
      },
      "outputs": [],
      "source": [
        "import os, json, time, math, re, traceback, datetime, textwrap, random\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "\n",
        "import requests\n",
        "\n",
        "from langchain.tools import tool\n",
        "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "from tavily import TavilyClient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6dUjMQvKp_i"
      },
      "source": [
        "#### **2) API KEYS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-wjEguOIdbH"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"enter yours\"\n",
        "os.environ[\"GROQ_API_KEY\"]   = \"enter yours\"\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"enter yours\"\n",
        "os.environ[\"SERPAPI_API_KEY\"]= \"enter yours\"  # optional fallback\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OIqgKnaKhLB"
      },
      "source": [
        "#### **3) GLOBAL CONFIG**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "LeKGNmlfIgNO"
      },
      "outputs": [],
      "source": [
        "OUTPUT_MD   = \"Report.md\"\n",
        "OUTPUT_JSON = \"trip_plan.json\"\n",
        "\n",
        "SEARCH_QUERIES_TMPL = [\n",
        "    \"best things to do in {city} 2024 2025\",\n",
        "    \"best restaurants in {city} 2024 2025\",\n",
        "    \"free activities in {city} 2024 2025\",\n",
        "    \"hidden gems in {city} 2024 2025\",\n",
        "    \"local food specialties in {city} 2024 2025\"\n",
        "]\n",
        "\n",
        "DEFAULTS = {\n",
        "    \"place_radius_m\": 4000,               # search radius around destination center\n",
        "    \"max_candidates\": 30,                 # max places pulled per category\n",
        "    \"top_k\": 8,                           # final number of stops (including food & fun) before the end destination\n",
        "    \"transport_mode\": \"driving\",          # driving | walking | cycling\n",
        "    \"cost_per_km\": 0.25,                  # simple cost model (fuel/transport) — tweak as you like\n",
        "    \"time_value_per_hr\": 5.0              # optional time value ($/hr) to penalize long routes\n",
        "}\n",
        "\n",
        "STATE = {\n",
        "    \"inputs\": {},\n",
        "    \"search_sources\": [], # Tavily links (context)\n",
        "    \"places\": [],         # unified candidates (from SerpAPI or Overpass)\n",
        "    \"route\": {},          # solution with ordering/distances/cost\n",
        "    \"itinerary_md\": \"\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teInPxflKXNO"
      },
      "source": [
        "#### **4) LLM HELPERS (OpenAI primary, Groq fallback elsewhere)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "yyeKZI7KIizA"
      },
      "outputs": [],
      "source": [
        "def get_openai_llm(model=\"gpt-4o-mini\", temperature=0):\n",
        "    return ChatOpenAI(model=model, temperature=temperature, timeout=120)\n",
        "\n",
        "def get_groq_llm(model=\"llama-3.1-8b-instant\", temperature=0):\n",
        "    return ChatGroq(model_name=model, temperature=temperature, timeout=120)\n",
        "\n",
        "def get_groq2_llm(model=\"llama3-70b-8192\", temperature=0):\n",
        "    return ChatGroq(model_name=model, temperature=temperature, timeout=120)\n",
        "\n",
        "def llm_call(messages, openai_model=\"gpt-4o-mini\", groq_model=\"llama-3.1-8b-instant\", groq2_model=\"llama3-70b-8192\"):\n",
        "    \"\"\"\n",
        "    Generic LLM call for summaries/extraction: try OpenAI, then Groq, then Groq-70B.\n",
        "    (Your tool-calling agent still uses OpenAI inside run_agent.)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return get_openai_llm(openai_model).invoke(messages).content\n",
        "    except Exception as e1:\n",
        "        print(\"OpenAI failed, falling back to Groq:\", e1)\n",
        "        try:\n",
        "            return get_groq_llm(groq_model).invoke(messages).content\n",
        "        except Exception as e2:\n",
        "            print(\"Groq 8B failed, falling back to Groq 70B:\", e2)\n",
        "            try:\n",
        "                return get_groq2_llm(groq2_model).invoke(messages).content\n",
        "            except Exception as e3:\n",
        "                print(\"All LLMs failed:\", e3)\n",
        "                return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnOj15YKKREo"
      },
      "source": [
        "#### **5) BASIC GEO UTILITIES (Geocoding & Helpers)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "VzhP63OVIlpL"
      },
      "outputs": [],
      "source": [
        "def geocode_nominatim(q: str) -> Optional[Tuple[float,float,str]]:\n",
        "    # OpenStreetMap Nominatim (no key; be nice)\n",
        "    url = \"https://nominatim.openstreetmap.org/search\"\n",
        "    params = {\"q\": q, \"format\": \"json\", \"limit\": 1}\n",
        "    headers = {\"User-Agent\": \"Colab-Travel-Agent/1.0\"}\n",
        "    try:\n",
        "        r = requests.get(url, params=params, headers=headers, timeout=20)\n",
        "        r.raise_for_status()\n",
        "        data = r.json()\n",
        "        if data:\n",
        "            lat = float(data[0][\"lat\"]); lon = float(data[0][\"lon\"])\n",
        "            disp = data[0].get(\"display_name\", q)\n",
        "            return lat, lon, disp\n",
        "    except Exception as e:\n",
        "        print(\"geocode_nominatim error:\", e)\n",
        "    return None\n",
        "\n",
        "def haversine_km(a: Tuple[float,float], b: Tuple[float,float]) -> float:\n",
        "    R = 6371.0\n",
        "    lat1, lon1 = map(math.radians, a)\n",
        "    lat2, lon2 = map(math.radians, b)\n",
        "    dlat = lat2 - lat1; dlon = lon2 - lon1\n",
        "    h = math.sin(dlat/2)**2 + math.cos(lat1)*math.cos(lat2)*math.sin(dlon/2)**2\n",
        "    return 2*R*math.asin(math.sqrt(h))\n",
        "\n",
        "def multi_geocode(query: str):\n",
        "    \"\"\"\n",
        "    Try plain Nominatim, then city-biased, then Photon.\n",
        "    Returns (lat, lon, label) or None.\n",
        "    \"\"\"\n",
        "    # 1) plain Nominatim\n",
        "    hit = geocode_nominatim(query)\n",
        "    if hit:\n",
        "        return hit\n",
        "    # 2) Photon fallback\n",
        "    hit = geocode_photon(query)\n",
        "    if hit:\n",
        "        return hit\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "6jEX2qa0QeRQ"
      },
      "outputs": [],
      "source": [
        "# ======================\n",
        "# 5.1) CITY-BIASED GEOCODING HELPERS (Nominatim + Photon fallback)\n",
        "# ======================\n",
        "import math\n",
        "\n",
        "_GEO_UA = {\"User-Agent\": \"Colab-Travel-Agent/1.1 (+no-keys)\"}\n",
        "\n",
        "def _bbox_from_center(lat: float, lon: float, box_km: float = 12.0):\n",
        "    \"\"\"Return (lon_min, lat_min, lon_max, lat_max) for a square ~box_km around center.\"\"\"\n",
        "    dlat = box_km / 111.0\n",
        "    dlon = box_km / (111.0 * max(0.1, math.cos(math.radians(lat))))\n",
        "    return (lon - dlon, lat - dlat, lon + dlon, lat + dlat)\n",
        "\n",
        "def geocode_nominatim_boxed(query: str, center_lat: float, center_lon: float, box_km: float = 12.0):\n",
        "    \"\"\"Nominatim geocoding biased to a city area via viewbox + bounded=1.\"\"\"\n",
        "    lon_min, lat_min, lon_max, lat_max = _bbox_from_center(center_lat, center_lon, box_km)\n",
        "    url = \"https://nominatim.openstreetmap.org/search\"\n",
        "    params = {\n",
        "        \"q\": query,\n",
        "        \"format\": \"json\",\n",
        "        \"limit\": 1,\n",
        "        \"viewbox\": f\"{lon_min},{lat_min},{lon_max},{lat_max}\",\n",
        "        \"bounded\": 1,\n",
        "        \"addressdetails\": 0,\n",
        "    }\n",
        "    try:\n",
        "        r = requests.get(url, params=params, headers=_GEO_UA, timeout=20)\n",
        "        r.raise_for_status()\n",
        "        data = r.json()\n",
        "        if data:\n",
        "            return float(data[0][\"lat\"]), float(data[0][\"lon\"]), data[0].get(\"display_name\", query)\n",
        "    except Exception as e:\n",
        "        print(\"geocode_nominatim_boxed error:\", e)\n",
        "    return None\n",
        "\n",
        "def geocode_photon(query: str):\n",
        "    \"\"\"Photon (Komoot) fallback — no key.\"\"\"\n",
        "    url = \"https://photon.komoot.io/api/\"\n",
        "    try:\n",
        "        r = requests.get(url, params={\"q\": query, \"limit\": 1}, headers=_GEO_UA, timeout=20)\n",
        "        r.raise_for_status()\n",
        "        js = r.json()\n",
        "        feats = js.get(\"features\") or []\n",
        "        if feats:\n",
        "            coords = feats[0][\"geometry\"][\"coordinates\"]  # [lon, lat]\n",
        "            lat, lon = float(coords[1]), float(coords[0])\n",
        "            label = feats[0][\"properties\"].get(\"name\", query)\n",
        "            return lat, lon, label\n",
        "    except Exception as e:\n",
        "        print(\"geocode_photon error:\", e)\n",
        "    return None\n",
        "\n",
        "def geocode_in_city(query_fragment: str, city_center: tuple, box_km: float = 12.0):\n",
        "    \"\"\"\n",
        "    Resolve a short/vague spot (e.g., 'liberty market') within the city\n",
        "    by biasing geocoding to a viewbox around the city center.\n",
        "    \"\"\"\n",
        "    latc, lonc = city_center\n",
        "    hit = geocode_nominatim_boxed(query_fragment, latc, lonc, box_km=box_km)\n",
        "    if hit:\n",
        "        return hit\n",
        "    return geocode_photon(query_fragment)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMG8yIEMKFg1"
      },
      "source": [
        "#### **6) SEARCH (Tavily) — context | guides about destination**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "frRYCsUjIo7v"
      },
      "outputs": [],
      "source": [
        "def tavily_search_city(city: str, k: int = 5) -> List[Dict[str, str]]:\n",
        "    out = []\n",
        "    try:\n",
        "        tv = TavilyClient(api_key=os.environ.get(\"TAVILY_API_KEY\",\"\"))\n",
        "        for q in SEARCH_QUERIES_TMPL:\n",
        "            query = q.format(city=city)\n",
        "            res = tv.search(query=query, search_depth=\"advanced\", include_answer=False, max_results=max(3, k), days=365)\n",
        "            for item in res.get(\"results\", []):\n",
        "                out.append({\"title\": item.get(\"title\",\"\"), \"url\": item.get(\"url\",\"\"), \"content\": (item.get(\"content\",\"\") or \"\")[:400]})\n",
        "            time.sleep(0.3)\n",
        "    except Exception as e:\n",
        "        print(\"Tavily search failed:\", e)\n",
        "    return out[:k*len(SEARCH_QUERIES_TMPL)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvLPQ2_WJ5B-"
      },
      "source": [
        "#### **7) PLACES DISCOVERY**\n",
        "*    *SerpAPI Google Maps (preferred if key provided)*\n",
        "*    *Overpass (OSM) fallback*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "NgI2aVMSIstL"
      },
      "outputs": [],
      "source": [
        "def serpapi_maps_places(query: str, lat: float, lon: float, radius_m: int, max_n: int) -> List[Dict[str, Any]]:\n",
        "    api_key = os.environ.get(\"SERPAPI_API_KEY\",\"\")\n",
        "    if not api_key or \"YOUR_\" in api_key:\n",
        "        return []\n",
        "    url = \"https://serpapi.com/search.json\"\n",
        "    params = {\n",
        "        \"engine\": \"google_maps\",\n",
        "        \"type\": \"search\",\n",
        "        \"q\": query,\n",
        "        \"ll\": f\"@{lat},{lon},15z\",\n",
        "        \"api_key\": api_key\n",
        "    }\n",
        "    try:\n",
        "        r = requests.get(url, params=params, timeout=30)\n",
        "        r.raise_for_status()\n",
        "        data = r.json()\n",
        "        results = data.get(\"local_results\", []) or data.get(\"places\", [])\n",
        "        out = []\n",
        "        for x in results[:max_n]:\n",
        "            # Standardize fields\n",
        "            name = x.get(\"title\") or x.get(\"name\")\n",
        "            rating = x.get(\"rating\") or x.get(\"gps_coordinates\",{}).get(\"rating\") or x.get(\"rating_score\")\n",
        "            review_cnt = x.get(\"reviews\") or x.get(\"user_ratings_total\") or x.get(\"reviews_count\")\n",
        "            address = x.get(\"address\") or x.get(\"address_lines\") or x.get(\"full_address\")\n",
        "            coords = x.get(\"gps_coordinates\") or {}\n",
        "            plat, plon = coords.get(\"latitude\"), coords.get(\"longitude\")\n",
        "            price_level = x.get(\"price\") or x.get(\"price_level\")\n",
        "            link = x.get(\"link\") or x.get(\"website\") or x.get(\"cid\")\n",
        "            types = x.get(\"type\") or x.get(\"types\") or []\n",
        "            out.append({\n",
        "                \"name\": name, \"lat\": plat, \"lon\": plon, \"rating\": rating, \"reviews\": review_cnt,\n",
        "                \"price_level\": price_level, \"address\": address, \"types\": types,\n",
        "                \"source\": \"serpapi_google_maps\", \"url\": link or \"\"\n",
        "            })\n",
        "        return [p for p in out if p[\"lat\"] and p[\"lon\"]]\n",
        "    except Exception as e:\n",
        "        print(\"serpapi_maps_places error:\", e)\n",
        "        return []\n",
        "\n",
        "def overpass_query(lat: float, lon: float, radius_m: int, query: str) -> List[Dict[str, Any]]:\n",
        "    # query can be 'restaurant' or 'attraction'\n",
        "    if query == \"restaurant\":\n",
        "        q = f\"\"\"\n",
        "        [out:json];\n",
        "        node(around:{radius_m},{lat},{lon})[amenity=restaurant];\n",
        "        out center 50;\n",
        "        \"\"\"\n",
        "    else:\n",
        "        # \"things to do\" proxy: tourism=attraction + sightseeing: yes\n",
        "        q = f\"\"\"\n",
        "        [out:json];\n",
        "        (\n",
        "          node(around:{radius_m},{lat},{lon})[tourism=attraction];\n",
        "          node(around:{radius_m},{lat},{lon})[amenity=park];\n",
        "          node(around:{radius_m},{lat},{lon})[leisure=park];\n",
        "        );\n",
        "        out center 70;\n",
        "        \"\"\"\n",
        "    try:\n",
        "        r = requests.post(\"https://overpass-api.de/api/interpreter\", data=q, timeout=60)\n",
        "        r.raise_for_status()\n",
        "        data = r.json()\n",
        "        out = []\n",
        "        for e in data.get(\"elements\", []):\n",
        "            tags = e.get(\"tags\", {})\n",
        "            out.append({\n",
        "                \"name\": tags.get(\"name\") or \"Unnamed\",\n",
        "                \"lat\": e.get(\"lat\"), \"lon\": e.get(\"lon\"),\n",
        "                \"rating\": None, \"reviews\": None,\n",
        "                \"price_level\": None,\n",
        "                \"address\": tags.get(\"addr:full\") or \"\",\n",
        "                \"types\": [tags.get(\"amenity\") or tags.get(\"tourism\") or tags.get(\"leisure\")],\n",
        "                \"source\": \"overpass_osm\",\n",
        "                \"url\": f\"https://www.openstreetmap.org/node/{e.get('id')}\"\n",
        "            })\n",
        "        return [p for p in out if p[\"lat\"] and p[\"lon\"]]\n",
        "    except Exception as e:\n",
        "        print(\"overpass error:\", e)\n",
        "        return []\n",
        "\n",
        "def get_places(lat: float, lon: float, radius_m: int, max_n: int) -> List[Dict[str,Any]]:\n",
        "    out = []\n",
        "    # Prefer SerpAPI if available\n",
        "    ser_ok = os.environ.get(\"SERPAPI_API_KEY\",\"\") and \"YOUR_\" not in os.environ.get(\"SERPAPI_API_KEY\",\"\")\n",
        "    if ser_ok:\n",
        "        out += serpapi_maps_places(\"things to do\", lat, lon, radius_m, max_n)\n",
        "        out += serpapi_maps_places(\"restaurants\",  lat, lon, radius_m, max_n)\n",
        "    # Fallback to Overpass to ensure we have something\n",
        "    if len(out) < 10:\n",
        "        out += overpass_query(lat, lon, radius_m, \"attraction\")\n",
        "        out += overpass_query(lat, lon, radius_m, \"restaurant\")\n",
        "    # de-dup by name+coords\n",
        "    seen = set()\n",
        "    uniq = []\n",
        "    for p in out:\n",
        "        key = (p[\"name\"], round(p[\"lat\"],5), round(p[\"lon\"],5))\n",
        "        if key not in seen:\n",
        "            seen.add(key)\n",
        "            uniq.append(p)\n",
        "    return uniq[:max_n*2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "Q3b4XjLrQjEH"
      },
      "outputs": [],
      "source": [
        "# ======================\n",
        "# 7.1) SPECIFIC POI FINDER (café / pharmacy / restroom / cuisine or anything!) via Overpass\n",
        "# ======================\n",
        "import re\n",
        "\n",
        "def find_specific_places(center_lat: float, center_lon: float, radius_m: int, query_text: str):\n",
        "    \"\"\"\n",
        "    Returns list of {name, lat, lon, category, address, url}\n",
        "    Supports amenity keywords and cuisine (e.g. 'italian', 'pakistani').\n",
        "    \"\"\"\n",
        "    if not query_text:\n",
        "        return []\n",
        "\n",
        "    txt = query_text.lower().strip()\n",
        "    synonyms = {\n",
        "        \"cafe\": [\"cafe\", \"coffee\", \"coffee shop\", \"chai\"],\n",
        "        \"market\": [\"bazar\", \"grocery\", \"shop stop\", \"mart\"],\n",
        "        \"fuel\": [\"CNG\", \"petrol pump\", \"gas station\"],\n",
        "        \"pharmacy\": [\"pharmacy\", \"hospital\", \"clinic\"],\n",
        "        \"restroom\": [\"restroom\", \"toilet\", \"washroom\", \"toilets\", \"bathroom\"],\n",
        "        \"restaurant\": [\"restaurant\", \"eatery\", \"food\", \"diner\", \"lunch\", \"takeaway\"],\n",
        "    }\n",
        "    amenity = None\n",
        "    cuisine = None\n",
        "\n",
        "    tokens = [t for t in re.split(r\"[,/; ]+\", txt) if t]\n",
        "    for k, words in synonyms.items():\n",
        "        if any(w in tokens for w in words):\n",
        "            amenity = {\"cafe\":\"cafe\", \"pharmacy\":\"pharmacy\", \"restroom\":\"toilets\", \"restaurant\":\"restaurant\"}[k]\n",
        "            break\n",
        "\n",
        "    cuisine_words = {\"pakistani\",\"italian\",\"chinese\",\"japanese\",\"thai\",\"indian\",\"turkish\",\"korean\",\"mexican\",\"french\",\"arabic\",\"lebanese\",\"bbq\",\"seafood\",\"vegan\",\"vegetarian\",\"bakery\",\"dessert\"}\n",
        "    guessed = [w for w in tokens if w in cuisine_words]\n",
        "    if guessed:\n",
        "        cuisine = \"|\".join(guessed)\n",
        "        if amenity is None:\n",
        "            amenity = \"restaurant\"\n",
        "\n",
        "    if amenity is None and not cuisine:\n",
        "        amenity = \"restaurant\"\n",
        "        cuisine = \"|\".join(tokens)  # treat unknown words as cuisine pattern\n",
        "\n",
        "    filters = []\n",
        "    if amenity:\n",
        "        filters.append(f'[amenity=\"{amenity}\"]')\n",
        "    if cuisine:\n",
        "        filters.append(f'[cuisine~\"{cuisine}\",i]')\n",
        "\n",
        "    overpass = f\"\"\"\n",
        "    [out:json][timeout:60];\n",
        "    (\n",
        "      node(around:{radius_m},{center_lat},{center_lon}){''.join(filters)};\n",
        "      way(around:{radius_m},{center_lat},{center_lon}){''.join(filters)};\n",
        "      relation(around:{radius_m},{center_lat},{center_lon}){''.join(filters)};\n",
        "    );\n",
        "    out center 100;\n",
        "    \"\"\"\n",
        "    try:\n",
        "        r = requests.post(\"https://overpass-api.de/api/interpreter\", data=overpass, timeout=90)\n",
        "        r.raise_for_status()\n",
        "        data = r.json()\n",
        "        out = []\n",
        "        for e in data.get(\"elements\", []):\n",
        "            tags = e.get(\"tags\", {}) or {}\n",
        "            lat = e.get(\"lat\") or (e.get(\"center\", {}) or {}).get(\"lat\")\n",
        "            lon = e.get(\"lon\") or (e.get(\"center\", {}) or {}).get(\"lon\")\n",
        "            if not (lat and lon):\n",
        "                continue\n",
        "            name = tags.get(\"name\") or (cuisine if cuisine else amenity) or \"Unnamed\"\n",
        "            address = tags.get(\"addr:full\") or \"\"\n",
        "            url = f\"https://www.openstreetmap.org/{e.get('type','node')}/{e.get('id')}\"\n",
        "            out.append({\n",
        "                \"name\": name,\n",
        "                \"lat\": float(lat),\n",
        "                \"lon\": float(lon),\n",
        "                \"category\": \"specific\",\n",
        "                \"address\": address,\n",
        "                \"url\": url\n",
        "            })\n",
        "        return out\n",
        "    except Exception as e:\n",
        "        print(\"find_specific_places error:\", e)\n",
        "        return []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "YBL7F2J-2zWj"
      },
      "outputs": [],
      "source": [
        "# ===== 7.3) Execute parsed intents: SerpAPI (Google Maps) -> Nominatim/Overpass fallback =====\n",
        "\n",
        "def _serpapi_maps_search(q: str, lat: float, lon: float, max_n: int = 10):\n",
        "    api_key = os.environ.get(\"SERPAPI_API_KEY\",\"\")\n",
        "    if not api_key:\n",
        "        return []\n",
        "    url = \"https://serpapi.com/search.json\"\n",
        "    params = {\n",
        "        \"engine\": \"google_maps\",\n",
        "        \"type\": \"search\",\n",
        "        \"q\": q,\n",
        "        \"ll\": f\"@{lat},{lon},15z\",\n",
        "        \"api_key\": api_key\n",
        "    }\n",
        "    try:\n",
        "        r = requests.get(url, params=params, timeout=30)\n",
        "        r.raise_for_status()\n",
        "        data = r.json()\n",
        "        results = data.get(\"local_results\", []) or data.get(\"places\", [])\n",
        "        out = []\n",
        "        for x in results[:max_n]:\n",
        "            name = x.get(\"title\") or x.get(\"name\") or q\n",
        "            coords = x.get(\"gps_coordinates\") or {}\n",
        "            plat, plon = coords.get(\"latitude\"), coords.get(\"longitude\")\n",
        "            addr = x.get(\"address\") or x.get(\"address_lines\") or \"\"\n",
        "            link = x.get(\"link\") or x.get(\"website\") or \"\"\n",
        "            types = x.get(\"type\") or x.get(\"types\") or []\n",
        "            if plat and plon:\n",
        "                out.append({\n",
        "                    \"name\": name, \"lat\": float(plat), \"lon\": float(plon),\n",
        "                    \"category\": \"specific\", \"address\": addr, \"types\": types,\n",
        "                    \"source\": \"serpapi_google_maps\", \"url\": link\n",
        "                })\n",
        "        return out\n",
        "    except Exception as e:\n",
        "        print(\"SerpAPI search error:\", e)\n",
        "        return []\n",
        "\n",
        "def _nominatim_box_search(q: str, center_xy, box_km: float = 15.0, limit: int = 10):\n",
        "    # bias Nominatim to the city area via viewbox\n",
        "    latc, lonc = center_xy\n",
        "    def _bbox(lat, lon, box_km):\n",
        "        dlat = box_km / 111.0\n",
        "        dlon = box_km / (111.0 * max(0.1, math.cos(math.radians(lat))))\n",
        "        return (lon - dlon, lat - dlat, lon + dlon, lat + dlat)\n",
        "    lon_min, lat_min, lon_max, lat_max = _bbox(latc, lonc, box_km)\n",
        "    url = \"https://nominatim.openstreetmap.org/search\"\n",
        "    params = {\n",
        "        \"q\": q, \"format\": \"json\", \"limit\": limit,\n",
        "        \"viewbox\": f\"{lon_min},{lat_min},{lon_max},{lat_max}\",\n",
        "        \"bounded\": 1\n",
        "    }\n",
        "    try:\n",
        "        r = requests.get(url, params=params, headers={\"User-Agent\":\"TravelAgent/1.2\"}, timeout=30)\n",
        "        r.raise_for_status()\n",
        "        rows = r.json() or []\n",
        "        out = []\n",
        "        for row in rows:\n",
        "            out.append({\n",
        "                \"name\": row.get(\"display_name\", q),\n",
        "                \"lat\": float(row[\"lat\"]), \"lon\": float(row[\"lon\"]),\n",
        "                \"category\": \"specific\", \"address\": row.get(\"display_name\",\"\"),\n",
        "                \"types\": [], \"source\": \"nominatim\", \"url\": f\"https://www.openstreetmap.org/{row.get('osm_type','node')}/{row.get('osm_id','')}\"\n",
        "            })\n",
        "        return out\n",
        "    except Exception as e:\n",
        "        print(\"Nominatim search error:\", e)\n",
        "        return []\n",
        "\n",
        "def _overpass_osm_tag(center_xy, radius_m, key: str, value: str, limit: int = 40):\n",
        "    lat, lon = center_xy\n",
        "    overpass = f\"\"\"\n",
        "    [out:json][timeout:60];\n",
        "    (\n",
        "      node(around:{radius_m},{lat},{lon})[{key}=\"{value}\"];\n",
        "      way(around:{radius_m},{lat},{lon})[{key}=\"{value}\"];\n",
        "      relation(around:{radius_m},{lat},{lon})[{key}=\"{value}\"];\n",
        "    );\n",
        "    out center {limit};\n",
        "    \"\"\"\n",
        "    try:\n",
        "        r = requests.post(\"https://overpass-api.de/api/interpreter\", data=overpass, timeout=90)\n",
        "        r.raise_for_status()\n",
        "        data = r.json() or {}\n",
        "        out = []\n",
        "        for e in data.get(\"elements\", []):\n",
        "            tags = e.get(\"tags\", {}) or {}\n",
        "            plat = e.get(\"lat\") or (e.get(\"center\", {}) or {}).get(\"lat\")\n",
        "            plon = e.get(\"lon\") or (e.get(\"center\", {}) or {}).get(\"lon\")\n",
        "            if not (plat and plon):\n",
        "                continue\n",
        "            name = tags.get(\"name\") or value\n",
        "            url = f\"https://www.openstreetmap.org/{e.get('type','node')}/{e.get('id')}\"\n",
        "            out.append({\n",
        "                \"name\": name, \"lat\": float(plat), \"lon\": float(plon),\n",
        "                \"category\": \"specific\", \"address\": tags.get(\"addr:full\",\"\"),\n",
        "                \"types\": [f\"{key}={value}\"], \"source\": \"overpass_osm\", \"url\": url\n",
        "            })\n",
        "        return out\n",
        "    except Exception as e:\n",
        "        print(\"Overpass (OSM tag) error:\", e)\n",
        "        return []\n",
        "\n",
        "def resolve_parsed_specific_requests(center_xy, radius_m, parsed_items, max_per_item: int = 10):\n",
        "    \"\"\"\n",
        "    For each parsed item:\n",
        "      - 'place'/'area': SerpAPI → Nominatim (city-biased) → multi_geocode (guarantee 1)\n",
        "      - 'category' (with optional cuisine): SerpAPI → Nominatim\n",
        "      - 'osm' tag: Overpass direct\n",
        "    Returns normalized places list (each tagged with category='specific').\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    latc, lonc = center_xy\n",
        "\n",
        "    for it in (parsed_items or []):\n",
        "        t = (it.get(\"type\") or \"\").lower()\n",
        "        if t == \"place\":\n",
        "            q = it.get(\"name\",\"\").strip()\n",
        "            if not q:\n",
        "                continue\n",
        "            # 1) SerpAPI\n",
        "            got = _serpapi_maps_search(q, latc, lonc, max_n=max_per_item)\n",
        "            # 2) Nominatim (city box)\n",
        "            if not got:\n",
        "                got = _nominatim_box_search(q, center_xy, limit=max_per_item)\n",
        "            # 3) multi_geocode (guarantee at least one point)\n",
        "            if not got:\n",
        "                hit = geocode_in_city(q, center_xy) or multi_geocode(q)\n",
        "                if hit:\n",
        "                    plat, plon, label = hit\n",
        "                    got = [{\n",
        "                        \"name\": label, \"lat\": float(plat), \"lon\": float(plon),\n",
        "                        \"category\": \"specific\", \"address\": label,\n",
        "                        \"types\": [\"user_specified\",\"place\"],\n",
        "                        \"source\": \"geocode_fallback\", \"url\": \"\"\n",
        "                    }]\n",
        "            # tag & add\n",
        "            for p in (got or []):\n",
        "                p.setdefault(\"category\",\"specific\")\n",
        "            out.extend(got or [])\n",
        "\n",
        "        elif t == \"area\":\n",
        "            q = it.get(\"name\",\"\").strip()\n",
        "            if not q:\n",
        "                continue\n",
        "            got = _nominatim_box_search(q, center_xy, limit=max_per_item)\n",
        "            for p in (got or []):\n",
        "                p.setdefault(\"category\",\"specific\")\n",
        "            out.extend(got or [])\n",
        "\n",
        "        elif t == \"category\":\n",
        "            lbl = (it.get(\"label\") or \"\").strip()\n",
        "            cuisine = (it.get(\"cuisine\") or \"\").strip()\n",
        "            if not lbl:\n",
        "                continue\n",
        "            q = f\"{cuisine} {lbl}\".strip() if cuisine else lbl\n",
        "            got = _serpapi_maps_search(q, latc, lonc, max_n=max_per_item) or _nominatim_box_search(q, center_xy, limit=max_per_item)\n",
        "            for p in (got or []):\n",
        "                p.setdefault(\"category\",\"specific\")\n",
        "            out.extend(got or [])\n",
        "\n",
        "        elif t == \"osm\":\n",
        "            key = (it.get(\"key\") or \"\").strip(); value = (it.get(\"value\") or \"\").strip()\n",
        "            if key and value:\n",
        "                got = _overpass_osm_tag(center_xy, radius_m, key, value, limit=max_per_item)\n",
        "                for p in (got or []):\n",
        "                    p.setdefault(\"category\",\"specific\")\n",
        "                out.extend(got or [])\n",
        "\n",
        "    # de‑dup by (name, lat, lon)\n",
        "    dedup, seen = [], set()\n",
        "    for p in out:\n",
        "        key = (p.get(\"name\",\"\"), round(float(p.get(\"lat\",0) or 0),5), round(float(p.get(\"lon\",0) or 0),5))\n",
        "        if key not in seen:\n",
        "            seen.add(key); dedup.append(p)\n",
        "    return dedup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOKqZWPhJza3"
      },
      "source": [
        "#### **8) OSRM ROUTING (distance/time & route)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "GYbgGvP1Iv6X"
      },
      "outputs": [],
      "source": [
        "def osrm_table(coords: List[Tuple[float,float]], mode=\"driving\") -> Dict[str, Any]:\n",
        "    base = f\"https://router.project-osrm.org/table/v1/{mode}/\"\n",
        "    path = \";\".join([f\"{lon},{lat}\" for lat,lon in coords])\n",
        "    url = base + path\n",
        "    try:\n",
        "        r = requests.get(url, params={\"annotations\":\"duration,distance\"}, timeout=60)\n",
        "        r.raise_for_status()\n",
        "        # OSRM returns null for unreachable destinations. Need to handle this.\n",
        "        data = r.json()\n",
        "        # Replace None in distances/durations with a large number (or handle later)\n",
        "        dist_matrix = data.get(\"distances\")\n",
        "        dur_matrix = data.get(\"durations\")\n",
        "\n",
        "        if dist_matrix:\n",
        "            for row in dist_matrix:\n",
        "                for i in range(len(row)):\n",
        "                    if row[i] is None:\n",
        "                        row[i] = float('inf') # Treat unreachable as infinite distance\n",
        "        if dur_matrix:\n",
        "            for row in dur_matrix:\n",
        "                 for i in range(len(row)):\n",
        "                     if row[i] is None:\n",
        "                         row[i] = float('inf') # Treat unreachable as infinite duration # Use inf for duration too\n",
        "\n",
        "        return {\"distances\": dist_matrix, \"durations\": dur_matrix}\n",
        "    except Exception as e:\n",
        "        print(\"osrm_table error:\", e)\n",
        "        return {}\n",
        "\n",
        "def osrm_route_summary(a: Tuple[float,float], b: Tuple[float,float], mode=\"driving\") -> Optional[Tuple[float,float]]:\n",
        "    base = f\"https://router.project-osrm.org/route/v1/{mode}/\"\n",
        "    url  = base + f\"{a[1]},{a[0]};{b[1]},{b[0]}\"\n",
        "    try:\n",
        "        r = requests.get(url, params={\"overview\":\"false\",\"alternatives\":\"false\",\"steps\":\"false\",\"annotations\":\"false\"}, timeout=60)\n",
        "        r.raise_for_status()\n",
        "        data = r.json()\n",
        "        routes = data.get(\"routes\", [])\n",
        "        if routes:\n",
        "            dist_m = routes[0].get(\"distance\", 0.0)\n",
        "            dur_s  = routes[0].get(\"duration\", 0.0)\n",
        "            return dist_m, dur_s\n",
        "    except Exception as e:\n",
        "        print(\"osrm_route_summary error:\", e)\n",
        "    return None\n",
        "\n",
        "# Simple greedy TSP (start fixed at origin, end fixed at destination)\n",
        "def plan_route(origin: Tuple[float,float], dest: Tuple[float,float], stops: List[Dict[str,Any]], mode=\"driving\") -> Dict[str,Any]:\n",
        "    # Build coords: origin + stops + dest\n",
        "    coords = [origin] + [(p[\"lat\"], p[\"lon\"]) for p in stops if p and p.get(\"lat\") is not None and p.get(\"lon\") is not None] + [dest]\n",
        "\n",
        "    # Ensure at least origin and destination are present\n",
        "    if len(coords) < 2:\n",
        "        print(\"plan_route: Not enough valid coordinates for routing.\")\n",
        "        # Return a minimal valid route structure indicating failure or no stops\n",
        "        return {\"order\": [0, 1], \"legs\": [{\"from_index\": 0, \"to_index\": 1, \"distance_m\": 0.0, \"duration_s\": 0.0}], \"total_distance_m\": 0.0, \"total_duration_s\": 0.0}\n",
        "\n",
        "\n",
        "    table = osrm_table(coords, mode=mode)\n",
        "    dist = table.get(\"distances\")\n",
        "    dur  = table.get(\"durations\")\n",
        "\n",
        "    # Fallback to pairwise haversine if OSRM table failed or returned no data\n",
        "    if not dist or not dur or any(any(x is None for x in row) for row in dist) or any(any(x is None for x in row) for row in dur):\n",
        "        print(\"OSRM table failed or returned None/invalid data. Falling back to Haversine.\")\n",
        "        n = len(coords)\n",
        "        dist = [[0.0]*n for _ in range(n)]\n",
        "        dur  = [[0.0]*n for _ in range(n)]\n",
        "        speed_kmh = 40 if mode==\"driving\" else (5 if mode==\"walking\" else 15)\n",
        "        for i in range(n):\n",
        "            for j in range(n):\n",
        "                if i==j: continue\n",
        "                try:\n",
        "                    d = haversine_km(coords[i], coords[j])\n",
        "                    dist[i][j] = d*1000.0 # Convert to meters\n",
        "                    dur[i][j]  = (d/speed_kmh)*3600.0 # Convert to seconds\n",
        "                except Exception as e:\n",
        "                    print(f\"Haversine calculation failed for {coords[i]} to {coords[j]}: {e}\")\n",
        "                    dist[i][j] = float('inf')\n",
        "                    dur[i][j] = float('inf')\n",
        "\n",
        "\n",
        "    # Ensure dist and dur are lists of lists of numbers/inf\n",
        "    if not isinstance(dist, list) or not all(isinstance(row, list) for row in dist) or \\\n",
        "       not isinstance(dur, list) or not all(isinstance(row, list) for row in dur):\n",
        "        print(\"Fallback Haversine calculation failed to produce valid matrices.\")\n",
        "        # Return minimal failed route\n",
        "        return {\"order\": [0, len(coords)-1] if len(coords)>1 else [0], \"legs\": [], \"total_distance_m\": float('inf'), \"total_duration_s\": float('inf')}\n",
        "\n",
        "\n",
        "    # greedy: from origin (0) to choose next closest among stops, end at last index (n-1) enforced\n",
        "    n = len(coords)\n",
        "    must_end = n-1\n",
        "    # Indices of stops in the coords list are from 1 to n-2\n",
        "    unvisited_indices_in_coords = set(range(1, n-1))\n",
        "    route_indices_in_coords = [0] # Start at origin (index 0 in coords)\n",
        "\n",
        "    curr_idx_in_coords = 0 # Start at origin\n",
        "\n",
        "    while unvisited_indices_in_coords:\n",
        "        # Find the next unvisited index in coords that minimizes distance from current\n",
        "        # Safely handle potential None or non-numeric in dist matrix lookup\n",
        "        try:\n",
        "            next_idx_in_coords = min(\n",
        "                unvisited_indices_in_coords,\n",
        "                key=lambda j: dist[curr_idx_in_coords][j] if isinstance(dist[curr_idx_in_coords][j], (int, float)) else float('inf')\n",
        "            )\n",
        "            route_indices_in_coords.append(next_idx_in_coords)\n",
        "            unvisited_indices_in_coords.remove(next_idx_in_coords)\n",
        "            curr_idx_in_coords = next_idx_in_coords\n",
        "        except Exception as e:\n",
        "            print(f\"Error during greedy TSP next step selection: {e}. Remaining unvisited: {unvisited_indices_in_coords}\")\n",
        "            # Break out of loop if min operation fails\n",
        "            break\n",
        "\n",
        "    # Ensure the route ends at the destination (must_end)\n",
        "    if route_indices_in_coords[-1] != must_end:\n",
        "         # If the last point added wasn't the destination, add it now\n",
        "         if must_end not in route_indices_in_coords:\n",
        "              route_indices_in_coords.append(must_end)\n",
        "         else:\n",
        "             # If destination was visited somewhere in the middle, ensure it's also the final stop\n",
        "             # This simple greedy doesn't handle visiting the end stop mid-route well.\n",
        "             # For robustness, if destination was visited, we might simplify the route to just origin -> destination\n",
        "             # Or, if it's not the last point, remove intermediate points after its first visit and add it again at the end.\n",
        "             # Simplest: if destination is in route but not last, make route origin -> destination.\n",
        "             # More complex: find last unvisited point, connect it to destination.\n",
        "             # Let's stick to simple: if the destination is in the route but not the end, force origin->destination route as a safe path.\n",
        "             if route_indices_in_coords[-1] != must_end: # Double check\n",
        "                print(\"Destination visited but not as final stop. Forcing origin -> destination route.\")\n",
        "                route_indices_in_coords = [0, must_end] # Simplest valid route\n",
        "\n",
        "    # accumulate totals\n",
        "    legs = []\n",
        "    total_dist_m = 0.0\n",
        "    total_dur_s  = 0.0\n",
        "    for i in range(len(route_indices_in_coords)-1):\n",
        "        a, b = route_indices_in_coords[i], route_indices_in_coords[i+1]\n",
        "        # Ensure distance/duration are numbers before accumulating\n",
        "        dist_val = dist[a][b] if isinstance(dist[a][b], (int, float)) else float('inf')\n",
        "        dur_val = dur[a][b] if isinstance(dur[a][b], (int, float)) else float('inf')\n",
        "\n",
        "        total_dist_m += dist_val\n",
        "        total_dur_s  += dur_val\n",
        "        legs.append({\"from_index\": a, \"to_index\": b, \"distance_m\": dist_val, \"duration_s\": dur_val})\n",
        "\n",
        "    # Map coords indices back to original \"order\" which includes origin/stops/destination\n",
        "    # The order needs to reference the indices in the original `coords` list (0 for origin, 1...n-2 for stops, n-1 for dest)\n",
        "    final_order_indices = route_indices_in_coords\n",
        "\n",
        "    return {\"order\": final_order_indices, \"legs\": legs, \"total_distance_m\": total_dist_m, \"total_duration_s\": total_dur_s}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-2R8GznJtlr"
      },
      "source": [
        "#### **9) FUN SCORE & SELECTION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "2u3pzvXBIyxd"
      },
      "outputs": [],
      "source": [
        "def normalize(x, lo, hi):\n",
        "    if hi <= lo: return 0.0\n",
        "    x = max(lo, min(hi, x))\n",
        "    return (x - lo) / (hi - lo)\n",
        "\n",
        "def compute_fun_scores(places: List[Dict[str,Any]], center: Tuple[float,float]) -> List[Dict[str,Any]]:\n",
        "    max_reviews = max([p.get(\"reviews\", 0) or 0 for p in places] + [1]) # Use .get() here\n",
        "\n",
        "    # map price symbols to numeric\n",
        "    def price_to_num(v):\n",
        "        if v is None: return 2\n",
        "        s = str(v)\n",
        "        if s.isdigit(): return int(s)\n",
        "        return s.count(\"$\") if \"$\" in s else 2\n",
        "\n",
        "    scored = []\n",
        "    for p in places:\n",
        "        # Use .get() with default values\n",
        "        rating = float(p.get(\"rating\", 0.0)) if p.get(\"rating\") not in [None,\"\"] else 0.0\n",
        "        reviews = float(p.get(\"reviews\", 0)) if p.get(\"reviews\") not in [None,\"\"] else 0.0 # Use .get() here\n",
        "        price = price_to_num(p.get(\"price_level\")) # Use .get() here\n",
        "        # Ensure lat/lon are valid before computing distance\n",
        "        if p.get(\"lat\") is None or p.get(\"lon\") is None:\n",
        "            dist_km = float('inf') # Or handle as needed, setting to inf makes it less likely to be picked\n",
        "        else:\n",
        "            dist_km = haversine_km(center, (p[\"lat\"], p[\"lon\"]))\n",
        "\n",
        "        s_rating  = normalize(rating, 3.5, 5.0)           # favor 4.0+\n",
        "        s_pop     = normalize(math.log1p(reviews), 0, math.log1p(max_reviews))\n",
        "        s_close   = 1 - normalize(dist_km, 0, 8)          # closer is better\n",
        "        s_price   = 1 - normalize(price, 1, 4)            # cheaper is better\n",
        "\n",
        "        fun = 0.46*s_rating + 0.32*s_pop + 0.14*s_close + 0.08*s_price\n",
        "        p2 = dict(p); p2[\"fun_score\"] = round(fun, 4); p2[\"dist_from_center_km\"] = round(dist_km, 2)\n",
        "        scored.append(p2)\n",
        "\n",
        "    # diversify by type: interleave top N from two buckets (food vs fun)\n",
        "    food  = [p for p in scored if any(t for t in (p.get(\"types\") or []) if \"restaurant\" in str(t).lower() or \"food\" in str(t).lower())]\n",
        "    funs  = [p for p in scored if p not in food]\n",
        "    food.sort(key=lambda x: x[\"fun_score\"], reverse=True)\n",
        "    funs.sort(key=lambda x: x[\"fun_score\"], reverse=True)\n",
        "\n",
        "    return food, funs, scored"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24WCPRB-Joxl"
      },
      "source": [
        "#### **10) LANGCHAIN TOOLS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "R2rhcOMQIKh6"
      },
      "outputs": [],
      "source": [
        "@tool(\"geo_destination\")\n",
        "def geo_destination_tool(query: str) -> dict:\n",
        "    \"\"\"Geocode a destination or address into latitude/longitude and a nice display name.\"\"\"\n",
        "    res = geocode_nominatim(query)\n",
        "    return {\"ok\": bool(res), \"lat\": res[0] if res else None, \"lon\": res[1] if res else None, \"label\": res[2] if res else None}\n",
        "\n",
        "@tool(\"discover_places\")\n",
        "def discover_places_tool(lat: float, lon: float, radius_m: int = DEFAULTS[\"place_radius_m\"], max_candidates: int = DEFAULTS[\"max_candidates\"]) -> dict:\n",
        "    \"\"\"Find restaurants and attractions near the destination using SerpAPI (if available) with Overpass fallback.\"\"\"\n",
        "    places = get_places(lat, lon, radius_m, max_candidates)\n",
        "    STATE[\"places\"] = places\n",
        "    return {\"count\": len(places)}\n",
        "\n",
        "@tool(\"discover_places\")\n",
        "def discover_places_tool(\n",
        "    lat: float,\n",
        "    lon: float,\n",
        "    radius_m: int = DEFAULTS[\"place_radius_m\"],\n",
        "    max_candidates: int = DEFAULTS[\"max_candidates\"],\n",
        ") -> dict:\n",
        "    \"\"\"Find restaurants/attractions near the destination and MERGE with any existing specific spots.\"\"\"\n",
        "    new_places = get_places(lat, lon, radius_m, max_candidates)\n",
        "\n",
        "    # preserve any 'specific' items already in STATE[\"places\"] (from your specific-need search)\n",
        "    keep_specific = [p for p in STATE.get(\"places\", []) if p.get(\"category\") == \"specific\"]\n",
        "\n",
        "    merged = keep_specific + (new_places or [])\n",
        "    # de‑dup by (name, lat, lon)\n",
        "    uniq, seen = [], set()\n",
        "    for p in merged:\n",
        "        key = (p.get(\"name\",\"\"), round(float(p.get(\"lat\",0) or 0), 5), round(float(p.get(\"lon\",0) or 0), 5))\n",
        "        if key not in seen:\n",
        "            seen.add(key); uniq.append(p)\n",
        "\n",
        "    STATE[\"places\"] = uniq\n",
        "    return {\n",
        "        \"count\": len(STATE[\"places\"]),\n",
        "        \"added_now\": len(new_places or []),\n",
        "        \"preserved_specific\": len(keep_specific),\n",
        "    }\n",
        "\n",
        "# ===== Section 10: pick_and_route_tool — REPLACE =====\n",
        "@tool(\"pick_and_route\")\n",
        "def pick_and_route_tool(\n",
        "    origin_query: str,\n",
        "    dest_query: str,\n",
        "    top_k: int = DEFAULTS[\"top_k\"],\n",
        "    mode: str = DEFAULTS[\"transport_mode\"],\n",
        "    cost_per_km: float = DEFAULTS[\"cost_per_km\"],\n",
        "    time_value_per_hr: float = DEFAULTS[\"time_value_per_hr\"],\n",
        ") -> dict:\n",
        "    \"\"\"Select top-K stops and compute a low-cost route from origin → stops → destination.\"\"\"\n",
        "    g1 = geocode_nominatim(origin_query); g2 = geocode_nominatim(dest_query)\n",
        "    if not g1 or not g2 or not STATE.get(\"places\"):\n",
        "        return {\"ok\": False, \"error\": \"Missing geocodes or places.\"}\n",
        "\n",
        "    origin = (g1[0], g1[1]); dest = (g2[0], g2[1])\n",
        "    center = dest\n",
        "\n",
        "    food, funs, scored = compute_fun_scores(STATE[\"places\"], center)\n",
        "\n",
        "    picks: List[Dict[str, Any]] = []\n",
        "\n",
        "    # 1) If user asked for something, FORCE‑include the nearest 'specific' candidate\n",
        "    want_specific = bool(STATE[\"inputs\"].get(\"specific_need_free\"))\n",
        "    if want_specific:\n",
        "        specifics = [p for p in scored if (p.get(\"category\") == \"specific\") and (p.get(\"lat\") is not None) and (p.get(\"lon\") is not None)]\n",
        "        if specifics:\n",
        "            specifics.sort(key=lambda p: p.get(\"dist_from_center_km\", 9e9))\n",
        "            picks.append(specifics[0])\n",
        "\n",
        "    # 2) Fill the rest by interleaving fun + food, avoiding dupes\n",
        "    i = j = 0\n",
        "    def _already(p):\n",
        "        return any(haversine_km((p[\"lat\"], p[\"lon\"]), (q[\"lat\"], q[\"lon\"])) <= 0.01 for q in picks)\n",
        "\n",
        "    while len(picks) < max(2, top_k) and (i < len(funs) or j < len(food)):\n",
        "        if i < len(funs):\n",
        "            cand = funs[i]; i += 1\n",
        "            if cand.get(\"lat\") is not None and cand.get(\"lon\") is not None and not _already(cand):\n",
        "                picks.append(cand)\n",
        "        if len(picks) >= top_k: break\n",
        "        if j < len(food):\n",
        "            cand = food[j]; j += 1\n",
        "            if cand.get(\"lat\") is not None and cand.get(\"lon\") is not None and not _already(cand):\n",
        "                picks.append(cand)\n",
        "\n",
        "    # 3) Route & cost\n",
        "    route = plan_route(origin, dest, picks, mode=mode)\n",
        "    total_km = route[\"total_distance_m\"] / 1000.0\n",
        "    total_hr = route[\"total_duration_s\"] / 3600.0\n",
        "    cost_est = total_km * max(0.0, float(cost_per_km)) + total_hr * max(0.0, float(time_value_per_hr))\n",
        "\n",
        "    # 4) Human-readable order\n",
        "    ordered = []\n",
        "    all_nodes = [{\"name\": \"Origin\", \"lat\": origin[0], \"lon\": origin[1], \"url\": \"\"}] + picks + [{\"name\": \"Destination\", \"lat\": dest[0], \"lon\": dest[1], \"url\": \"\"}]\n",
        "    for idx in route[\"order\"]:\n",
        "        if 0 <= idx < len(all_nodes):\n",
        "            ordered.append(all_nodes[idx])\n",
        "\n",
        "    STATE[\"route\"] = {\n",
        "        \"mode\": mode,\n",
        "        \"origin_label\": g1[2],\n",
        "        \"destination_label\": g2[2],\n",
        "        \"stops\": picks,\n",
        "        \"order\": ordered,\n",
        "        \"legs\": route[\"legs\"],\n",
        "        \"total_distance_km\": round(total_km, 2),\n",
        "        \"total_duration_hr\": round(total_hr, 2),\n",
        "        \"estimated_total_cost\": round(cost_est, 2),\n",
        "        \"params\": {\"cost_per_km\": cost_per_km, \"time_value_per_hr\": time_value_per_hr},\n",
        "    }\n",
        "    return {\n",
        "        \"ok\": True,\n",
        "        \"summary\": {\n",
        "            \"distance_km\": STATE[\"route\"][\"total_distance_km\"],\n",
        "            \"duration_hr\": STATE[\"route\"][\"total_duration_hr\"],\n",
        "            \"cost_est\": STATE[\"route\"][\"estimated_total_cost\"],\n",
        "        },\n",
        "    }\n",
        "\n",
        "@tool(\"make_itinerary\")\n",
        "def make_itinerary_tool(preferences_json: str = \"\") -> str:\n",
        "    \"\"\"Generate a friendly Markdown itinerary based on the chosen route and sources.\"\"\"\n",
        "    prefs = preferences_json or \"{}\"\n",
        "\n",
        "    md_content = llm_call([\n",
        "        {\"role\": \"system\", \"content\": \"You are a cheerful but concise travel concierge. Keep it practical, use bullet points.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"\"\"\n",
        "Create a Markdown itinerary. Requirements:\n",
        "- Start with a short overview.\n",
        "- List the ordered stops with one-line reasons to visit and any known ratings if available.\n",
        "- Include total distance, duration, and a small budget breakdown using the provided cost estimate.\n",
        "- Add 6-8 quick tips (best time, booking, local transport, safety).\n",
        "- Finish with 'Sources' linking the discovery guides and place URLs.\n",
        "\n",
        "DATA (JSON):\n",
        "inputs: {json.dumps(STATE[\"inputs\"], ensure_ascii=False)}\n",
        "route: {json.dumps(STATE[\"route\"], ensure_ascii=False)}\n",
        "guides: {json.dumps(STATE[\"search_sources\"][:10], ensure_ascii=False)}\n",
        "places_note: \"Some places come from OSM and may not have ratings.\"\n",
        "\"\"\"}\n",
        "    ])\n",
        "\n",
        "    # If LLM call fails, make a minimal placeholder\n",
        "    if not md_content:\n",
        "        md_content = \"# Trip Itinerary\\n\\n(No AI-generated summary was available.)\"\n",
        "\n",
        "    STATE[\"itinerary_md\"] = md_content\n",
        "\n",
        "    # Always save Markdown and JSON, even on LLM failure\n",
        "    with open(OUTPUT_MD, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(STATE[\"itinerary_md\"])\n",
        "    with open(OUTPUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\n",
        "            \"inputs\": STATE[\"inputs\"],\n",
        "            \"guides\": STATE[\"search_sources\"],\n",
        "            \"places\": STATE[\"places\"],\n",
        "            \"route\": STATE[\"route\"],\n",
        "            \"generated_at\": datetime.datetime.utcnow().isoformat() + \"Z\"\n",
        "        }, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    return STATE[\"itinerary_md\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gypzp8qGJjQo"
      },
      "source": [
        "#### **11) AGENT PROMPT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "sp0lTD-EILiD"
      },
      "outputs": [],
      "source": [
        "SYSTEM_MSG = \"\"\"You are a multi-tool travel agent. Follow the plan:\n",
        "1) geo_destination(city) to validate destination.\n",
        "2) discover_guides(city) for recent lists/tips (last 12 months intent).\n",
        "3) discover_places(lat,lon) to fetch candidates.\n",
        "4) pick_and_route(origin, destination, top_k, mode, cost_per_km, time_value_per_hr).\n",
        "5) make_itinerary(preferences_json).\n",
        "\n",
        "Only call tools. When the route exists, call make_itinerary to finish.\n",
        "\"\"\"\n",
        "\n",
        "agent_tools = [geo_destination_tool, discover_guides_tool, discover_places_tool, pick_and_route_tool, make_itinerary_tool]\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", SYSTEM_MSG),\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\")\n",
        "])\n",
        "\n",
        "def run_agent(inputs: Dict[str,Any]):\n",
        "    if not os.environ.get(\"GROQ_API_KEY\"):\n",
        "        raise RuntimeError(\"No GROQ_API_KEY; skipping tool-calling agent.\")\n",
        "\n",
        "    msg = textwrap.dedent(f\"\"\"\n",
        "    User inputs (JSON):\n",
        "    {json.dumps(inputs, ensure_ascii=False)}\n",
        "    Begin the plan now starting with geo_destination.\n",
        "    \"\"\").strip()\n",
        "\n",
        "    llm = get_groq2_llm(\"llama3-70b-8192\", temperature=0)\n",
        "    agent = create_openai_tools_agent(llm, agent_tools, prompt)\n",
        "    executor = AgentExecutor(agent=agent, tools=agent_tools, verbose=True, handle_parsing_errors=True, max_iterations=20)\n",
        "    return executor.invoke({\"input\": msg})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0O51j4PJWQB"
      },
      "source": [
        "#### **12) COLLECT USER INPUTS (INTERACTIVE)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_EEoNPdJWlg",
        "outputId": "820773fa-c2bf-443f-a082-93c5d5655eb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧭 RouteForge here! craftsthe perfect route like a true navigator...\n",
            "Enter your ORIGIN (address or city): darulsalam addison illinois \n",
            "Enter your FINAL DESTINATION (address or city): cumming georgia\n",
            "City/Area to explore (press Enter to reuse final destination): \n",
            "Transport mode [driving/walking/cycling] (default driving): \n",
            "How many stops before the final destination? (default 8): 10\n",
            "Search radius in meters? (default 4000): \n",
            "Cost per km (e.g., fuel, fare) (default 0.25): 5\n",
            "Your time value per hour (default 5.0): \n"
          ]
        }
      ],
      "source": [
        "AGENT_NAME = \"RouteForge\"\n",
        "print(f\"🧭 {AGENT_NAME} here! craftsthe perfect route like a true navigator...\")\n",
        "origin = input(\"Enter your ORIGIN (address or city): \").strip()\n",
        "final_destination = input(\"Enter your FINAL DESTINATION (address or city): \").strip()\n",
        "city_for_guides = input(\"City/Area to explore (press Enter to reuse final destination): \").strip() or final_destination\n",
        "mode = input(\"Transport mode [driving/walking/cycling] (default driving): \").strip().lower() or DEFAULTS[\"transport_mode\"]\n",
        "try:\n",
        "    top_k = int(input(f\"How many stops before the final destination? (default {DEFAULTS['top_k']}): \").strip() or DEFAULTS[\"top_k\"])\n",
        "except:\n",
        "    top_k = DEFAULTS[\"top_k\"]\n",
        "try:\n",
        "    radius_m = int(input(f\"Search radius in meters? (default {DEFAULTS['place_radius_m']}): \").strip() or DEFAULTS[\"place_radius_m\"])\n",
        "except:\n",
        "    radius_m = DEFAULTS[\"place_radius_m\"]\n",
        "try:\n",
        "    cost_per_km = float(input(f\"Cost per km (e.g., fuel, fare) (default {DEFAULTS['cost_per_km']}): \").strip() or DEFAULTS[\"cost_per_km\"])\n",
        "except:\n",
        "    cost_per_km = DEFAULTS[\"cost_per_km\"]\n",
        "try:\n",
        "    time_value_per_hr = float(input(f\"Your time value per hour (default {DEFAULTS['time_value_per_hr']}): \").strip() or DEFAULTS[\"time_value_per_hr\"])\n",
        "except:\n",
        "    time_value_per_hr = DEFAULTS[\"time_value_per_hr\"]\n",
        "\n",
        "STATE[\"inputs\"] = {\n",
        "    \"origin\": origin,\n",
        "    \"final_destination\": final_destination,\n",
        "    \"city_for_guides\": city_for_guides,\n",
        "    \"mode\": mode,\n",
        "    \"top_k\": top_k,\n",
        "    \"radius_m\": radius_m,\n",
        "    \"cost_per_km\": cost_per_km,\n",
        "    \"time_value_per_hr\": time_value_per_hr\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "b833BXaKQo-g",
        "outputId": "359c0aad-a953-42f7-8102-e16d40c1b59d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Anything specific to find? (e.g., 'cafe' — press Enter to skip: i want to stop by a cafe and a flower shop\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'i want to stop by a cafe and a flower shop'"
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "STATE[\"inputs\"][\"specific_need_free\"] = input(\"Anything specific to find? (e.g., 'cafe' — press Enter to skip: \").strip()\n",
        "STATE[\"inputs\"].get(\"specific_need_free\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL-uzwTT2qXy",
        "outputId": "ad10b24e-18c2-4d2b-9044-7eaa6bc14960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI failed, falling back to Groq: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Parsed intents: [{'type': 'category', 'label': 'cafe', 'count': 1}, {'type': 'category', 'label': 'flower shop', 'count': 1}]\n"
          ]
        }
      ],
      "source": [
        "import json as _json\n",
        "\n",
        "def parse_specific_need_free(text: str):\n",
        "    if not text:\n",
        "        return []\n",
        "    # try LLM (OpenAI primary, Groq fallback) to get precise JSON\n",
        "    prompt = [\n",
        "        {\"role\":\"system\",\"content\":(\n",
        "            \"You convert a user's travel request into a compact JSON array of search intents. \"\n",
        "            \"Allowed item types: 'place', 'category', 'area', 'osm'. \"\n",
        "            \"Rules:\\n\"\n",
        "            \"- For a named business/venue, emit: {\\\"type\\\":\\\"place\\\",\\\"name\\\":\\\"...\\\"}\\n\"\n",
        "            \"- For categories, emit: {\\\"type\\\":\\\"category\\\",\\\"label\\\":\\\"cafe|pharmacy|restaurant|restroom|museum|park|mall|supermarket|...\\\",\\\"count\\\":<int optional>,\\\"cuisine\\\":\\\"italian|pakistani|...\\\" optional}\\n\"\n",
        "            \"- For an area inside the city (e.g., 'F-7', 'Liberty Market'), emit: {\\\"type\\\":\\\"area\\\",\\\"name\\\":\\\"...\\\"}\\n\"\n",
        "            \"- If you know the exact OSM tag, also add: {\\\"type\\\":\\\"osm\\\",\\\"key\\\":\\\"amenity|shop|tourism|leisure|...\\\",\\\"value\\\":\\\"toilets|pharmacy|supermarket|...\\\"}\\n\"\n",
        "            \"- Use 'restroom'→'toilets' for OSM vocabulary.\\n\"\n",
        "            \"Return ONLY valid JSON (no backticks, no text).\"\n",
        "        )},\n",
        "        {\"role\":\"user\",\"content\": f\"Query: {text}\\nReturn the JSON array now.\"}\n",
        "    ]\n",
        "    try:\n",
        "        raw = llm_call(prompt)  # uses your Section 4 helpers\n",
        "        obj = _json.loads(raw)\n",
        "        if isinstance(obj, list):\n",
        "            # normalize a bit\n",
        "            for it in obj:\n",
        "                if \"type\" in it: it[\"type\"] = it[\"type\"].lower()\n",
        "                if \"label\" in it and isinstance(it[\"label\"], str): it[\"label\"] = it[\"label\"].lower()\n",
        "                if \"name\" in it and isinstance(it[\"name\"], str): it[\"name\"] = it[\"name\"].strip()\n",
        "            return obj\n",
        "    except Exception as e:\n",
        "        print(\"Parser LLM failed; will search literally:\", e)\n",
        "    # fallback: treat entire text as a single place string\n",
        "    return [{\"type\":\"place\",\"name\":text.strip()}]\n",
        "\n",
        "STATE[\"inputs\"][\"specific_need_parsed\"] = parse_specific_need_free(STATE[\"inputs\"][\"specific_need_free\"])\n",
        "print(\"Parsed intents:\", STATE[\"inputs\"][\"specific_need_parsed\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pua3k-X1JQJs"
      },
      "source": [
        "#### **13) KICK OFF PIPELINE (Agent)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4pQXgwZSILlA",
        "outputId": "a151d3f2-4f2a-4e6b-f69c-caaa2aabc32a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running the agent...\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `geo_destination` with `{'query': 'cumming georgia'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m{'ok': True, 'lat': 34.2073196, 'lon': -84.1401926, 'label': 'Cumming, Forsyth County, Georgia, United States'}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `discover_guides` with `{'city': 'Cumming, Forsyth County, Georgia, United States'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m{'count': 25, 'samples': [{'title': 'THE 15 BEST Things to Do in Cumming (2025)', 'url': 'https://www.tripadvisor.com/Attractions-g34877-Activities-Cumming_Georgia.html', 'content': 'Top Attractions in Cumming ; 1. Sawnee Mountain Preserve · 4.6. (324) ; 2. Fowler Park · 4.8. (97) ; 3. Big Creek Greenway · 4.7. (145) ; 4. Cumming Aquatic Center.'}, {'title': 'Ultimate Local Guide To Cumming GA', 'url': 'https://www.goldpeachrealty.com/cumming-ga', 'content': 'As of 2024, the population of Cumming, Georgia, is approximately 7,300 people. The city is part of Forsyth County, which has seen significant growth in recent years.\\n\\n#### What are the top attractions in Cumming?\\n\\nTop attractions in Cumming include Sawnee Mountain Preserve, Fowler Park, Big Creek Greenway, Cumming Playhouse, and Cumming Aquatic Center. These destinations offer a mix of outdoor act'}, {'title': 'THE 10 BEST Things to Do in Forsyth (2025) - Must-See Attractions', 'url': 'https://www.tripadvisor.com/Attractions-g34951-Activities-Forsyth_Georgia.html', 'content': 'Top Attractions in Forsyth · 1. Monroe County Historic County Courthouse · 4.6 · 2. Monroe County Museum-Geneology. History Museums · 3. Forsyth United Methodist'}, {'title': 'Events from August 15 - City of Cumming', 'url': 'https://www.cityofcumming.net/events/list', 'content': \"City of Cumming\\nCity of Cumming\\n\\n### How Do I?\\n\\n### How Do I?\\n\\n### How Do I?\\n\\n### How Do I?\\n\\n### How Do I?\\n\\n### How Do I?\\n\\n## Events Search and Views Navigation\\n\\n### Event Views Navigation\\n\\n## August 2025\\n\\n### After School Special in Concert at City Center\\n\\nCome out to the City Center's Lou Sobh Amphitheater for this great, free concert featuring hits from the '90s!\\n\\n### Legends of Rock in Concert\"}, {'title': 'Calendar of Events | Explore Georgia', 'url': 'https://exploregeorgia.org/calendar-of-events', 'content': 'Type\\n African American Events\\n Antique, Craft & Hobby\\n Arts & Culture\\n Book Sales\\n Civil War Events\\n Culinary, Food, Wine & Beer\\n Entertainment\\n Fairs & Festivals\\n Family Friendly\\n Farmers Markets & Agritourism\\n Film Festivals & Events\\n Fishing & Hunting\\n Free Things to Do\\n GA250\\n Golf\\n Haunted\\n History & Heritage\\n Holidays\\n LGBT\\n Music & Concerts\\n Music Festival\\n Native American Events\\n Outdoors '}]}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `discover_places` with `{'lat': 34.2073196, 'lon': -84.1401926, 'max_candidates': 30, 'radius_m': 4000}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3m{'count': 61, 'added_now': 40, 'preserved_specific': 24}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `pick_and_route` with `{'cost_per_km': 5, 'dest_query': 'cumming georgia', 'mode': 'driving', 'origin_query': 'darulsalam addison illinois', 'time_value_per_hr': 5, 'top_k': 10}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m{'ok': False, 'error': 'Missing geocodes or places.'}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `geo_destination` with `{'query': 'darulsalam addison illinois'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m{'ok': False, 'lat': None, 'lon': None, 'label': None}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `geo_destination` with `{'query': 'darulsalam addison illinois'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m{'ok': False, 'lat': None, 'lon': None, 'label': None}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `pick_and_route` with `{'cost_per_km': 5, 'dest_query': 'cumming georgia', 'lat': 34.2073196, 'lon': -84.1401926, 'mode': 'driving', 'origin_query': '', 'time_value_per_hr': 5, 'top_k': 10}`\n",
            "responded: It seems like the origin location \"darulsalam addison illinois\" cannot be geocoded. Let's try to proceed with the destination location. \n",
            "\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m{'ok': False, 'error': 'Missing geocodes or places.'}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `geo_destination` with `{'query': 'darulsalam addison illinois'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m{'ok': False, 'lat': None, 'lon': None, 'label': None}\u001b[0m\n",
            "Agent failed or quota/rate-limit hit — deterministic fallback. Error code: 503 - {'error': {'message': 'Service unavailable. Visit https://groqstatus.com/ to see if there is an active incident.', 'type': 'internal_server_error'}}\n",
            "OpenAI failed, falling back to Groq: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        }
      ],
      "source": [
        "import datetime as dt_module\n",
        "\n",
        "try:\n",
        "    geo = geocode_nominatim(city_for_guides)\n",
        "    if not geo:\n",
        "        raise RuntimeError(\"Could not geocode the exploration city/area.\")\n",
        "    dlat, dlon, city_label = geo\n",
        "    center_xy = (dlat, dlon)\n",
        "\n",
        "    try:\n",
        "        city_bias_hit = geocode_in_city(STATE[\"inputs\"].get(\"city_for_guides\", city_for_guides), center_xy)\n",
        "        if city_bias_hit:\n",
        "            center_xy = (city_bias_hit[0], city_bias_hit[1])\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    parsed = STATE[\"inputs\"].get(\"specific_need_parsed\", [])\n",
        "    specific_places = resolve_parsed_specific_requests(center_xy, radius_m, parsed, max_per_item=12)\n",
        "\n",
        "    general_places = get_places(center_xy[0], center_xy[1], radius_m, DEFAULTS[\"max_candidates\"])\n",
        "\n",
        "    merged = (specific_places or []) + (general_places or [])\n",
        "    dedup, seen = [], set()\n",
        "    for p in merged:\n",
        "        k = (p.get(\"name\",\"\"), round(float(p.get(\"lat\",0) or 0),5), round(float(p.get(\"lon\",0) or 0),5))\n",
        "        if k not in seen:\n",
        "            seen.add(k); dedup.append(p)\n",
        "    STATE[\"places\"] = dedup\n",
        "\n",
        "    print(\"\\nRunning the agent...\")\n",
        "    result = run_agent({\n",
        "        \"origin\": origin,\n",
        "        \"destination\": final_destination,\n",
        "        \"city\": city_for_guides,\n",
        "        \"mode\": mode,\n",
        "        \"top_k\": top_k,\n",
        "        \"radius_m\": radius_m,\n",
        "        \"cost_per_km\": cost_per_km,\n",
        "        \"time_value_per_hr\": time_value_per_hr,\n",
        "        \"specific_need\": STATE[\"inputs\"].get(\"specific_need_free\",\"\")\n",
        "    })\n",
        "    final_md = result.get(\"output\") or result.get(\"final_output\") or STATE.get(\"itinerary_md\",\"\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"\\nAgent failed or quota/rate-limit hit — deterministic fallback.\", e)\n",
        "    # minimal fallback\n",
        "    if not STATE.get(\"places\"):\n",
        "        STATE[\"places\"] = get_places(center_xy[0], center_xy[1], radius_m, DEFAULTS[\"max_candidates\"])\n",
        "    _ = pick_and_route_tool.invoke({\n",
        "        \"origin_query\": origin,\n",
        "        \"dest_query\": final_destination,\n",
        "        \"top_k\": top_k,\n",
        "        \"mode\": mode,\n",
        "        \"cost_per_km\": cost_per_km,\n",
        "        \"time_value_per_hr\": time_value_per_hr\n",
        "    })\n",
        "    final_md = make_itinerary_tool.invoke({\"preferences_json\": json.dumps(STATE[\"inputs\"])})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM388dCUJHv_"
      },
      "source": [
        "#### **14) DONE — SHOW OUTPUT PATHS & PREVIEW**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUBIV8DLILnx",
        "outputId": "166912b7-9064-45b3-eac0-d4c2f4b8a593"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================== DONE ====================\n",
            "Markdown itinerary saved to: /content/Report.md\n",
            "JSON (sources & route) saved to: /content/trip_plan.json\n",
            "\n",
            "--- Report.md (preview) ---\n",
            "\n",
            "**Cumming, Georgia Road Trip Itinerary**\n",
            "=====================================\n",
            "\n",
            "### Overview\n",
            "\n",
            "Embark on a 4-day road trip from Darulsalam, Illinois to Cumming, Georgia, exploring the city's top attractions, cafes, and flower shops. This itinerary includes a mix of outdoor activities, cultural experiences, and delicious food.\n",
            "\n",
            "### Ordered Stops\n",
            "\n",
            "1. **Sawnee Mountain Preserve** (4.6/5) - Hike and enjoy scenic views of the surrounding mountains.\n",
            "2. **Fowler Park** (4.8/5) - Visit the park's playground, picnic areas, and walking trails.\n",
            "3. **Big Creek Greenway** (4.7/5) - Explore the 5.5-mile trail for hiking, biking, or walking.\n",
            "4. **Cumming Aquatic Center** - Cool off during the summer months with a swim or splash pad.\n",
            "5. **Tam's Backstage** (4.5/5) - Savor Southern cuisine and live music at this popular restaurant.\n",
            "6. **Marie's Italian Deli** (4.5/5) - Treat yourself to Italian sandwiches and pastries.\n",
            "7. **Giorgio's Family Kitchen** (4.3/5) - Enjoy family-style Italian dining with a cozy atmosphere.\n",
            "8. **Gardenia Mediterranean** (4.5/5) - Discover authentic Mediterranean flavors and cuisine.\n",
            "\n",
            "### Budget Breakdown\n",
            "\n",
            "* Gas: $200 (estimated 1,000 miles, $0.20/km)\n",
            "* Accommodation: $500 (avg. $125/night for 4 nights)\n",
            "* Food: $300 (avg. $75/day for meals and snacks)\n",
            "* Attractions: $100 (avg. $25/attraction for 4 days)\n",
            "* Total: $1,100\n",
            "\n",
            "### Quick Tips\n",
            "\n",
            "* **Best Time to Visit**: September to November or March to May for mild weather.\n",
            "* **Booking**: Book accommodations and restaurants in advance to avoid peak season prices.\n",
            "* **Local Transport**: Rent a car for easy transportation around the city.\n",
            "* **Safety**: Be aware of traffic and pedestrian rules, especially in busy areas.\n",
            "* **Cafe and Flower Shop Visits**: Plan to visit these specific locations on Day 2 and 3, respectively.\n",
            "* **Events**: Check the City of Cumming's events calendar for free concerts and festivals.\n",
            "* **Explore Georgia**: Visit the Explore Georgia website for a calendar of events and attractions.\n",
            "\n",
            "### Sources\n",
            "\n",
            "* [THE 15 BEST Things to Do in Cumming (2025)](https://www.tripadvisor.com/Attractions-g34877-Activities-Cumming_Georgia.html)\n",
            "* [Ultimate Local Guide To Cumming GA](https://www.goldpeachrealty.com/cumming-ga)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n==================== DONE ====================\")\n",
        "print(f\"Markdown itinerary saved to: {os.path.abspath(OUTPUT_MD)}\")\n",
        "print(f\"JSON (sources & route) saved to: {os.path.abspath(OUTPUT_JSON)}\")\n",
        "\n",
        "try:\n",
        "    with open(OUTPUT_MD, \"r\", encoding=\"utf-8\") as f:\n",
        "        preview = \"\".join([next(f) for _ in range(40)])\n",
        "    print(\"\\n--- Report.md (preview) ---\\n\")\n",
        "    print(preview)\n",
        "except Exception as e:\n",
        "    print(\"No preview available:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "bllTmLJWdGjA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
